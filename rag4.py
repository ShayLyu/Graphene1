import os
import streamlit as st
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from dotenv import load_dotenv
import json
import re
from openai import OpenAI
from langchain.embeddings.base import Embeddings
from typing import List
import requests
from langchain.agents import initialize_agent, Tool, AgentType
from langchain.tools import tool

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()
DASHSCOPE_API_KEY = os.environ.get('DASHSCOPE_API_KEY')
BOCHA_API_KEY = os.environ.get('BOCHA_API_KEY')
BOCHA_BASE_URL = os.environ.get('BOCHA_BASE_URL', 'https://api.bochaai.com/search')
DASHSCOPE_BASE_URL = "https://dashscope.aliyuncs.com/compatible-mode/v1"


# å®šä¹‰QwenEmbeddingsç±»
class QwenEmbeddings(Embeddings):
    def __init__(
            self,
            api_key: str = None,
            model: str = "text-embedding-v3",
            base_url: str = "https://dashscope.aliyuncs.com/compatible-mode/v1",
            dimensions: int = 1024
    ):
        self.client = OpenAI(
            api_key=api_key or DASHSCOPE_API_KEY,
            base_url=base_url,
        )
        self.model = model
        self.dimensions = dimensions

    def embed_documents(self, texts: List[str]) -> List[List[float]]:
        """å°†æ–‡æ¡£è½¬æ¢ä¸ºå‘é‡"""
        try:
            texts = [str(text) for text in texts]
            response = self.client.embeddings.create(
                model=self.model,
                input=texts,
                dimensions=self.dimensions,
                encoding_format="float"
            )
            return [item.embedding for item in response.data]
        except Exception as e:
            print(f"Embedding error in embed_documents: {e}")
            raise

    def embed_query(self, text: str) -> List[float]:
        """å°†æŸ¥è¯¢è½¬æ¢ä¸ºå‘é‡"""
        try:
            text = str(text)
            response = self.client.embeddings.create(
                model=self.model,
                input=[text],
                dimensions=self.dimensions,
                encoding_format="float"
            )
            return response.data[0].embedding
        except Exception as e:
            print(f"Embedding error in embed_query: {e}")
            raise


# å®šä¹‰Bocha Web Searchå·¥å…·
@tool
def bocha_websearch_tool(query: str, count: int = 10) -> str:
    """
    ä½¿ç”¨Bocha Web Search API è¿›è¡Œç½‘é¡µæœç´¢ã€‚

    å‚æ•°:
    - query: æœç´¢å…³é”®è¯
    - count: è¿”å›çš„æœç´¢ç»“æœæ•°é‡

    è¿”å›:
    - æœç´¢ç»“æœçš„è¯¦ç»†ä¿¡æ¯ï¼ŒåŒ…æ‹¬ç½‘é¡µæ ‡é¢˜ã€ç½‘é¡µURLã€ç½‘é¡µæ‘˜è¦ã€ç½‘ç«™åç§°ã€ç½‘ç«™Iconã€ç½‘é¡µå‘å¸ƒæ—¶é—´ç­‰ã€‚
    """
    url = 'https://api.bochaai.com/v1/web-search'
    headers = {
        'Authorization': f'Bearer {BOCHA_API_KEY}',
        'Content-Type': 'application/json'
    }
    data = {
        "query": query,
        "freshness": "noLimit",
        "summary": True,
        "count": count
    }

    response = requests.post(url, headers=headers, json=data)

    if response.status_code == 200:
        json_response = response.json()
        try:
            if json_response.get("code") != 200 or not json_response.get("data"):
                return f"æœç´¢APIè¯·æ±‚å¤±è´¥ï¼ŒåŸå› æ˜¯: {json_response.get('msg', 'æœªçŸ¥é”™è¯¯')}"

            webpages = json_response["data"].get("webPages", {}).get("value", [])
            if not webpages:
                return "æœªæ‰¾åˆ°ç›¸å…³ç»“æœã€‚"
            formatted_results = ""
            for idx, page in enumerate(webpages, start=1):
                formatted_results += (
                    f"å¼•ç”¨: {idx}\n"
                    f"æ ‡é¢˜: {page.get('name', 'æ— æ ‡é¢˜')}\n"
                    f"URL: {page.get('url', 'æ— URL')}\n"
                    f"æ‘˜è¦: {page.get('summary', 'æ— æ‘˜è¦')}\n"
                    f"ç½‘ç«™åç§°: {page.get('siteName', 'æ— ç½‘ç«™åç§°')}\n"
                    f"ç½‘ç«™å›¾æ ‡: {page.get('siteIcon', 'æ— å›¾æ ‡')}\n"
                    f"å‘å¸ƒæ—¶é—´: {page.get('dateLastCrawled', 'æ— å‘å¸ƒæ—¶é—´')}\n\n"
                )
            return formatted_results.strip()
        except Exception as e:
            return f"æœç´¢APIè¯·æ±‚å¤±è´¥ï¼ŒåŸå› æ˜¯ï¼šæœç´¢ç»“æœè§£æå¤±è´¥ {str(e)}"
    else:
        return f"æœç´¢APIè¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}, é”™è¯¯ä¿¡æ¯: {response.text}"


# åˆ›å»ºBochaå·¥å…·
bocha_tool = Tool(
    name="BochaWebSearch",
    func=bocha_websearch_tool,
    description="ä½¿ç”¨Bocha Web Search API è¿›è¡Œæœç´¢äº’è”ç½‘ç½‘é¡µï¼Œè¾“å…¥åº”ä¸ºæœç´¢æŸ¥è¯¢å­—ç¬¦ä¸²ï¼Œè¾“å‡ºå°†è¿”å›æœç´¢ç»“æœçš„è¯¦ç»†ä¿¡æ¯ï¼ŒåŒ…æ‹¬ç½‘é¡µæ ‡é¢˜ã€ç½‘é¡µURLã€ç½‘é¡µæ‘˜è¦ã€ç½‘ç«™åç§°ã€ç½‘ç«™Iconã€ç½‘é¡µå‘å¸ƒæ—¶é—´ç­‰ã€‚"
)

# åˆå§‹åŒ–OpenAIè¯­è¨€æ¨¡å‹
llm = ChatOpenAI(
    model="qwen-plus",
    temperature=0,
    openai_api_key=DASHSCOPE_API_KEY,
    openai_api_base=DASHSCOPE_BASE_URL
)

# åˆå§‹åŒ–LangChainä»£ç†
agent = initialize_agent(
    tools=[bocha_tool],
    llm=llm,
    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
    verbose=True
)


class PDFKnowledgeBaseQA:
    def __init__(
            self,
            knowledge_base_path: str,
            model: str = 'qwen-max',
            embedding_model: str = 'text-embedding-v3',
            base_url: str = 'https://dashscope.aliyuncs.com/compatible-mode/v1',
            temperature: float = 0.7,
            top_p: float = 0.7,
    ):
        load_dotenv()

        self.knowledge_base_path = knowledge_base_path
        self.embeddings = QwenEmbeddings(
            model=embedding_model,
            base_url=base_url,
            api_key=DASHSCOPE_API_KEY
        )

        self.vectorstore = FAISS.load_local(
            knowledge_base_path,
            self.embeddings,
            allow_dangerous_deserialization=True
        )

        self.llm = ChatOpenAI(
            model=model,
            temperature=temperature,
            openai_api_base=base_url,
            openai_api_key=DASHSCOPE_API_KEY,
            extra_body={"enable_search": True}
        )

        # åˆå§‹åŒ–Bochaå·¥å…·
        self.agent = agent

    def _classify_question(self, query: str) -> str:
        """ä½¿ç”¨å¤§æ¨¡å‹å¯¹é—®é¢˜è¿›è¡Œåˆ†ç±»"""
        classification_prompt = f"""è¯·åˆ†æä»¥ä¸‹é—®é¢˜ï¼Œå¹¶å°†å…¶åˆ†ç±»ä¸ºä»¥ä¸‹å››ç§ç±»å‹ä¹‹ä¸€ï¼š
        1. expert_ranking: è¯¢é—®çŸ³å¢¨çƒ¯ä¸“å®¶ã€ä¸“å®¶æ’åã€å­¦è€…æ’åã€å‘æ˜äººæ’åã€ä¸“å®¶æ¨èã€ä¸“å®¶åˆ—ä¸¾ç­‰ï¼Œï¼ˆæ³¨æ„ä¸åŒ…æ‹¬ä»‹ç»æŸä½ä¸“å®¶çš„å…·ä½“ä¿¡æ¯ã€ç›´æ¥è¯¢é—®ä¸“å®¶çš„å§“åæ—¶ä¹Ÿä¸è¢«åˆ¤å®šä¸ºæ­¤ç±»ï¼‰
        2. company_recommendation_province: è¯¢é—®ä¸­åŒ…å«å…·ä½“çš„æŸä¸ªçœä»½ï¼Œä¼ä¸šæ¨èã€å…¬å¸æ¨èç­‰ï¼Œä¸€å®šåŒ…å«çœä»½ä¿¡æ¯æ‰èƒ½åˆ¤å®šæ˜¯è¿™ä¸ªç±»åˆ«
        3. company_application_recommendation: 
        è¯¢é—®å…·æœ‰XXXåº”ç”¨çš„ä¼ä¸šã€å“ªäº›ä¼ä¸šæœ‰XXXäº§å“ã€å“ªäº›ä¼ä¸šæœ‰XXXåº”ç”¨ç­‰ï¼Œ
        ä¾‹å¦‚ï¼šçŸ³å¢¨çƒ¯æ•£çƒ­è†œçš„ä¼ä¸šã€å“ªäº›ä¼ä¸šæœ‰æ•£çƒ­åº”ç”¨ã€ç¯ä¿åº”ç”¨çš„ä¼ä¸š
        å½“é—®åˆ°å•ç‹¬çš„äº§å“æˆ–åº”ç”¨æ—¶ä¸åˆ¤å®šä¸ºæ­¤ç±»ï¼Œæ¯”å¦‚ï¼šçŸ³å¢¨çƒ¯æ•£çƒ­ç­‰å•ç‹¬æ¦‚å¿µè€Œä¸æ¶‰åŠä¼ä¸šå’Œå…¬å¸ï¼Œè¯·ä¸è¦åˆ¤æ–­åˆ°è¿™ä¸€ç±»
        4. general_qa: å…¶ä»–å¸¸è§„é—®é¢˜ï¼ˆ
        çŸ³å¢¨çƒ¯æ•£çƒ­æ–¹é¢ï¼š
        åŒ…æ‹¬è¯¢é—®çŸ³å¢¨çƒ¯æ•£çƒ­æ–¹å‘çš„å„ç§é—®é¢˜ï¼šçŸ³å¢¨çƒ¯æ•£çƒ­çš„å¸‚åœºã€çŸ³å¢¨çƒ¯æ•£çƒ­çš„åº”ç”¨æœºä¼šåˆ†æã€çŸ³å¢¨çƒ¯æ•£çƒ­é¢†åŸŸçš„å‘å±•ç­–ç•¥ç­‰

        ç»Ÿè®¡ç›¸å…³çš„çŸ¥è¯†æ–¹é¢ï¼š
        åŒ…æ‹¬ä¼ä¸šæˆ–äº§ä¸šçš„æ•°é‡ã€æˆç«‹æ—¶é—´åˆ†å¸ƒã€åœ°ç†åˆ†å¸ƒã€ææ–™ç”Ÿäº§ã€ææ–™åº”ç”¨ã€è£…ç½®åŠæ£€æµ‹ä¸‰å¤§ç¯èŠ‚ç›¸å…³çš„ç»Ÿè®¡ã€ä¸“åˆ©æ–¹é¢çš„ç»Ÿè®¡ç­‰

        ä¸“å®¶æ–¹é¢ï¼š
        åŒ…æ‹¬è¯¢é—®æŸä½å…·ä½“ä¸“å®¶å…·ä½“ä¿¡æ¯ï¼ŒæŸé¢†åŸŸæœ‰å“ªäº›ä¸“å®¶ï¼ŒXXXä¸“å®¶æœ‰å“ªäº›ä¸“åˆ©ï¼Œ

        ä¼ä¸šæ–¹é¢ï¼š
        å½“é—®é¢˜åªæ˜¯è¯¢é—®çŸ³å¢¨çƒ¯çš„ç›¸å…³ä¼ä¸šï¼Œæ¯”å¦‚ï¼šä¼ä¸šæ¨èï¼ŒçŸ³å¢¨çƒ¯ä¼ä¸šæ¨èï¼ŒçŸ³å¢¨çƒ¯çš„ä¼ä¸šï¼ŒçŸ³å¢¨çƒ¯çš„é¾™å¤´ä¼ä¸šï¼ŒçŸ³å¢¨çƒ¯å¤´éƒ¨ä¼ä¸šï¼ŒçŸ³å¢¨çƒ¯ç›¸å…³çš„ä¼ä¸šç­‰
        çŸ³å¢¨çƒ¯ä¸€èˆ¬çŸ¥è¯†æ–¹é¢ï¼š
        æ¯”å¦‚çŸ³å¢¨çƒ¯æ˜¯ä»€ä¹ˆï¼ŒçŸ³å¢¨çƒ¯æœ‰æ¯’å—ç­‰


        )

        é—®é¢˜ï¼š{query}

        è¯·åªè¿”å›åˆ†ç±»ç»“æœï¼ˆexpert_ranking/company_recommendation_province/general_qa/company_application_recommendationï¼‰ï¼Œä¸è¦åŒ…å«å…¶ä»–å†…å®¹ã€‚"""

        try:
            result = self.llm.invoke(classification_prompt)
            classification = result.content.strip().lower()
            if classification in ['expert_ranking', 'company_recommendation_province', 'general_qa',
                                  'company_application_recommendation']:
                print('classification', classification)
                return classification
            return 'general_qa'
        except Exception as e:
            print(f"Classification error: {e}")
            return 'general_qa'

    def _get_relevant_documents(self, query: str, k: int = 10):
        """è·å–ç›¸å…³æ–‡æ¡£"""
        try:
            docs = self.vectorstore.similarity_search(query, k=k)
            return docs
        except Exception as e:
            print(f"Error getting relevant documents: {e}")
            return []

    def ask_question(self, query: str):
        """å¤„ç†ç”¨æˆ·é—®é¢˜å¹¶æ•´åˆä»£ç†çš„ç»“æœ"""
        try:
            # è·å–å¯ç”¨çš„çœä»½åˆ—è¡¨
            company_rankings_file = os.path.join('./data/jsonl/company_rankings.json')
            company_categoris_ranking_file = os.path.join('./data/jsonl/company_rankings_by_detailed_subcategory.json')
            with open(company_rankings_file, 'r', encoding='utf-8') as f:
                all_company_rankings = json.load(f)
            with open(company_categoris_ranking_file, 'r', encoding='utf-8') as f:
                all_company_categories_rankings = json.load(f)
            available_provinces = list(all_company_rankings.keys())
            available_categories = list(all_company_categories_rankings.keys())

            # ä½¿ç”¨å¤§æ¨¡å‹åˆ†ç±»é—®é¢˜
            question_type = self._classify_question(query)

            # è·å–ç›¸å…³æ–‡æ¡£
            relevant_docs = self._get_relevant_documents(query)

            if question_type in ['expert_ranking', 'company_recommendation_province',
                                 'company_application_recommendation']:
                # è®©ä»£ç†å¤„ç†è¿™äº›ç‰¹å®šç±»å‹çš„é—®é¢˜
                enhanced_query = f"åŸºäºä»¥ä¸‹ç”¨æˆ·é—®é¢˜å’Œç›¸å…³æ–‡æ¡£å†…å®¹ï¼Œç”Ÿæˆå‡†ç¡®çš„å›ç­”ã€‚\n\nç”¨æˆ·é—®é¢˜: {query}\n\nç›¸å…³æ–‡æ¡£å†…å®¹:\n" + "\n\n".join(
                    [doc.page_content for doc in relevant_docs])
                final_answer = self.agent.run(enhanced_query)
            else:
                # å¯¹äºå¸¸è§„é—®ç­”ï¼Œä½¿ç”¨ç°æœ‰çš„çŸ¥è¯†åº“å’Œä»£ç†
                if not relevant_docs:
                    final_answer = "æŠ±æ­‰ï¼Œæˆ‘æ²¡æœ‰æ‰¾åˆ°ç›¸å…³çš„æ–‡æ¡£ä¿¡æ¯æ¥å›ç­”æ‚¨çš„é—®é¢˜ã€‚"
                else:
                    context = "\n\n".join([doc.page_content for doc in relevant_docs])
                    enhanced_query = f"""åŸºäºä»¥ä¸‹ç›¸å…³æ–‡æ¡£å†…å®¹å›ç­”é—®é¢˜:

ç›¸å…³æ–‡æ¡£å†…å®¹:
{context}

ç”¨æˆ·é—®é¢˜: {query}

è¯·æ ¹æ®ä»¥ä¸Šä¿¡æ¯ç»™å‡ºå‡†ç¡®ã€ä¸“ä¸šçš„å›ç­”ã€‚
å¦‚æœä¿¡æ¯ä¸è¶³ï¼Œè¯·æ˜ç¡®æŒ‡å‡ºã€‚
å¦‚æœç”¨æˆ·é—®é¢†åŸŸç›¸å…³ï¼Œæœ‰å…³é”®å­—å»åˆå³å¯ï¼Œä¸éœ€è¦å®Œå…¨åŒ¹é…ã€‚

å½“æ¶‰åŠåˆ°çŸ³å¢¨çƒ¯çš„æ•£çƒ­é¢†åŸŸçŸ¥è¯†
1. è¯·ä»å¤šä¸ªè§’åº¦è¿›è¡Œå›å¤ï¼Œè®©å†…å®¹æ›´åŠ ä¸°å¯Œè¯¦ç»†
2. åˆ†æ¡ä½œç­”

å½“é—®åˆ°ä¸€äº›æ•°æ®ç»Ÿè®¡
1. è¯·å‚è€ƒç›¸å…³ä¿¡æ¯å›å¤

å½“æ¶‰åŠçš„çŸ³å¢¨çƒ¯çš„ä¸€èˆ¬é—®ç­”çŸ¥è¯†ï¼Œä¾‹å¦‚ï¼šçŸ³å¢¨çƒ¯æ˜¯ä»€ä¹ˆï¼ŒçŸ³å¢¨çƒ¯æœ‰æ¯’å—ç­‰
1. è¯·è¿›ä¸€æ­¥ä»‹ç»å›å¤ä¸­å‡ºç°çš„ä¸“æœ‰åè¯
2. ä»å¤šä¸ªè§’åº¦è¿›è¡Œå›å¤ï¼Œè®©å†…å®¹æ›´åŠ ä¸°å¯Œ
3. åˆ†æ¡ä½œç­”

å¦‚æœé—®é¢˜æ¶‰åŠåˆ°ä¼ä¸šï¼š
1. æ€»æ˜¯æŒ‰ä¼ä¸šçš„æ€»åˆ†æ’åºï¼ˆä»é«˜åˆ°åº•ï¼‰ç»™å‡ºå›å¤
2. é»˜è®¤ç»™å‡º6ä¸ªåˆ†æ•°åœ¨55åˆ°95ä¹‹é—´çš„ä¼ä¸š
3. è¯·ä¸è¦åœ¨å›å¤ä¸­æš´éœ²ä»¥ä¸Šéšè—ä¿¡æ¯ï¼Œè‡ªç„¶å›å¤å³å¯
"""
                    final_answer = self.agent.run(enhanced_query)

            return {
                'answer': final_answer,
                'sources': relevant_docs
            }

        except Exception as e:
            print(f"Error in ask_question: {e}")
            return {
                'error': str(e),
                'answer': "æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„è¯·æ±‚æ—¶å‡ºç°é”™è¯¯ã€‚",
                'sources': []
            }


def main():
    # è®¾ç½®é¡µé¢é…ç½®
    st.set_page_config(
        page_title="çŸ³å¢¨çƒ¯åŠ©æ‰‹",
        page_icon="â¬¡",
        layout="wide"
    )

    # è‡ªå®šä¹‰CSS
    st.markdown("""
    <style>
    .main-title {
        font-size: 36px;
        color: #2C3E50;
        text-align: center;
        margin-bottom: 20px;
    }
    .question-input {
        margin-bottom: 20px;
    }
    .answer-box {
        background-color: #F0F4F8;
        border-radius: 10px;
        padding: 20px;
        margin-top: 20px;
    }
    .source-box {
        background-color: #E9F5E9;
        border-radius: 10px;
        padding: 15px;
        margin-top: 10px;
    }
    .search-box {
        background-color: #FFFBE6;
        border-radius: 10px;
        padding: 15px;
        margin-top: 10px;
    }
    </style>
    """, unsafe_allow_html=True)

    # æ ‡é¢˜
    st.markdown("<h1 class='main-title'>çŸ³å¢¨çƒ¯çŸ¥è¯†åŠ©æ‰‹</h1>", unsafe_allow_html=True)

    # çŸ¥è¯†åº“è·¯å¾„
    knowledge_base_path = "./knowledge_base"

    # åˆå§‹åŒ– session_state
    if 'qa_system' not in st.session_state:
        st.session_state.qa_system = PDFKnowledgeBaseQA(
            knowledge_base_path,
            model='qwen-plus',
            base_url='https://dashscope.aliyuncs.com/compatible-mode/v1',
        )

    st.markdown("### ğŸ’¡ çŸ¥è¯†é—®ç­”")

    # ä½¿ç”¨ form æ¥æ§åˆ¶æäº¤
    with st.form(key='qa_form'):
        query = st.text_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜", placeholder="åœ¨è¿™é‡Œè¾“å…¥æ‚¨æƒ³äº†è§£çš„çŸ³å¢¨çƒ¯ç›¸å…³å†…å®¹...")
        submit_button = st.form_submit_button("æäº¤é—®é¢˜")

    # åªæœ‰åœ¨ç‚¹å‡»æäº¤æŒ‰é’®ä¸”æœ‰æŸ¥è¯¢å†…å®¹æ—¶æ‰å¤„ç†
    if submit_button and query:
        if 'last_query' not in st.session_state or st.session_state.last_query != query:
            with st.spinner('æ­£åœ¨ä¸ºæ‚¨æŸ¥æ‰¾ç­”æ¡ˆ...'):
                result = st.session_state.qa_system.ask_question(query)
                st.session_state.last_query = query
                st.session_state.last_result = result
        else:
            result = st.session_state.last_result

        print(result)
        st.markdown("<div class='answer-box'>", unsafe_allow_html=True)
        st.markdown("### ğŸ¤– æ™ºèƒ½å›å¤")
        st.write(result['answer'])
        st.markdown("</div>", unsafe_allow_html=True)

        if 'sources' in result and result['sources']:
            st.markdown("<div class='source-box'>", unsafe_allow_html=True)
            st.markdown("### ğŸ“„ ç›¸å…³æ–‡æ¡£ç‰‡æ®µ")

            for i, source in enumerate(result['sources'], 1):
                with st.expander(f"æ–‡æ¡£ç‰‡æ®µ {i}"):
                    st.markdown("**å†…å®¹é¢„è§ˆ:**")
                    st.write(source.page_content)
                    st.markdown("**æ–‡æ¡£ä¿¡æ¯:**")
                    st.write(f"æ–‡ä»¶: {source.metadata.get('source', 'æœªçŸ¥')}")
                    st.write(f"é¡µç : {source.metadata.get('page', 'æœªçŸ¥')}")
            st.markdown("</div>", unsafe_allow_html=True)

    # é¡µè„š
    st.markdown("---")
    st.markdown("ğŸ’¡ çŸ³å¢¨çƒ¯çŸ¥è¯†åŠ©æ‰‹ï¼šæ‚¨çš„çŸ³å¢¨çƒ¯ç ”ç©¶ä¸“å®¶")


if __name__ == "__main__":
    main()
